{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22942f7e-3446-4009-b551-cca7fcc25d73",
   "metadata": {},
   "source": [
    "# Reflexion\n",
    "\n",
    "https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/reflexion/reflexion.ipynb\n",
    "\n",
    "[Reflexion](https://arxiv.org/abs/2303.11366) by Shinn, et. al., is an architecture designed to learn through verbal feedback and self-reflection. The agent explicitly critiques its responses for tasks to generate a higher quality final response, at the expense of longer execution time.\n",
    "\n",
    "The paper outlines 3 main components:\n",
    "\n",
    "1. Actor (agent) with self-reflection\n",
    "2. External evaluator (task-specific, e.g. code compilation steps)\n",
    "3. Episodic memory that stores the reflections from (1).\n",
    "\n",
    "![reflexion](reflexion.png)\n",
    "In their code, the last two components are very task-specific, so in this notebook, you will build the _actor_ in LangGraph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906edf48-7c81-48b8-8250-fdc34043d01b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a917bb70-f84c-48e6-8d32-d14f9df2ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "MAX_CRITIQUES = 2\n",
    "MAX_ITERATIONS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3638c129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "import os\n",
    "\n",
    "llama_model = ChatOpenAI(\n",
    "    model=\"llama3.3\",\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "zhipu_model = ChatZhipuAI(\n",
    "    model=\"GLM-4-Plus\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "kimi_model = ChatOpenAI(\n",
    "    model=\"moonshot-v1-8k\",\n",
    "    api_key=os.environ[\"MOONSHOT_API_KEY\"],\n",
    "    base_url=\"https://api.moonshot.cn/v1\",\n",
    ")\n",
    "\n",
    "llms = [zhipu_model, kimi_model, llama_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af543598-52d0-4ec3-a05f-d2954ff793ee",
   "metadata": {},
   "source": [
    "## Actor (with reflection)\n",
    "\n",
    "The main component of Reflexion is the \"actor\", which is an agent that reflects on its response and re-executes to improve based on self-critique. It's main sub-components include:\n",
    "1. Tools/tool execution\n",
    "2. Initial responder: generate an initial response (and self-reflection)\n",
    "3. Revisor: re-respond (and reflec) based on previous reflections\n",
    "\n",
    "We'll first define the tool execution context.\n",
    "\n",
    "#### 1 Construct tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a2ac853-b8a6-40de-b7fe-3f9f3c5ca4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "# https://api.tavily.com\n",
    "tavily = TavilySearchResults(\n",
    "    api_wrapper=TavilySearchAPIWrapper(), max_results=5)\n",
    "\n",
    "# https://duckduckgo.com/\n",
    "duck_duck_go = DuckDuckGoSearchResults(\n",
    "    api_wrapper=DuckDuckGoSearchAPIWrapper(), max_results=5)\n",
    "\n",
    "search_tools = [tavily, tavily, duck_duck_go]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093fbaa0-9a71-4c32-9872-02a9aec9b35d",
   "metadata": {},
   "source": [
    "#### 2 Initial responder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa7aa4f-279e-4562-b1b5-6ce8391ef853",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <p class=\"admonition-title\">Using Pydantic with LangChain</p>\n",
    "    <p>\n",
    "        This notebook uses Pydantic v2 <code>BaseModel</code>, which requires <code>langchain-core >= 0.3</code>. Using <code>langchain-core < 0.3</code> will result in errors due to mixing of Pydantic v1 and v2 <code>BaseModels</code>.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fffa8d5-068a-4f0b-adfc-b4daf30ef294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langchain_core.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from pydantic import ValidationError\n",
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "\n",
    "\n",
    "class Reflection(BaseModel):\n",
    "    missing: str = Field(description=\"Critique of what is missing.\")\n",
    "    superfluous: str = Field(description=\"Critique of what is superfluous\")\n",
    "\n",
    "\n",
    "class AnswerQuestion(BaseModel):\n",
    "    \"\"\"Answer the question. Provide an answer, reflection, and then follow up with search queries to improve the answer.\"\"\"\n",
    "\n",
    "    answer: str = Field(\n",
    "        description=\"~250 word detailed answer to the question.\")\n",
    "    reflection: Reflection = Field(\n",
    "        description=\"Your reflection on the initial answer.\")\n",
    "    search_queries: list[str] = Field(\n",
    "        description=\"1-3 search queries for researching improvements to address the critique of your current answer.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ResponderWithRetries:\n",
    "    def __init__(self, runnable, validator):\n",
    "        self.runnable = runnable\n",
    "        self.validator = validator\n",
    "\n",
    "    def respond(self, state: list):\n",
    "        response = []\n",
    "        for attempt in range(MAX_CRITIQUES):\n",
    "            response = self.runnable.invoke(\n",
    "                {\"messages\": state[\"messages\"]}, {\n",
    "                    \"tags\": [f\"attempt:{attempt}\"]}\n",
    "            )\n",
    "            try:\n",
    "                self.validator.invoke(response)\n",
    "                return {\"messages\": response}\n",
    "            except ValidationError as e:\n",
    "                schema_json = json.dumps(self.validator.model_json_schema())\n",
    "                state[\"messages\"] += [\n",
    "                    response,\n",
    "                    ToolMessage(\n",
    "                        content=f\"{\n",
    "                            repr(e)}\\n\\nPay close attention to the function schema.\\n\\n\"\n",
    "                        + schema_json\n",
    "                        + \" Respond by fixing all validation errors.\",\n",
    "                        tool_call_id=response.tool_calls[0][\"id\"],\n",
    "                    ),\n",
    "                ]\n",
    "        return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a0264b8-ed2d-4f15-9d3c-085aa3a5edab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "actor_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are expert researcher.\n",
    "Current time: {time}\n",
    "\n",
    "1. {first_instruction}\n",
    "2. Reflect and critique your answer. Be severe to maximize improvement.\n",
    "3. Recommend search queries to research information and improve your answer.\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"\\n\\n<system>Reflect on the user's original question and the\"\n",
    "            \" actions taken thus far. Respond using the {function_name} function.</reminder>\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(\n",
    "    time=lambda: datetime.datetime.now().isoformat(),\n",
    ")\n",
    "initial_answer_chain = actor_prompt_template.partial(\n",
    "    first_instruction=\"Provide a detailed ~250 word answer.\",\n",
    "    function_name=AnswerQuestion.__name__,\n",
    ") | llms[0].bind_tools(tools=[AnswerQuestion])\n",
    "validator = PydanticToolsParser(tools=[AnswerQuestion])\n",
    "\n",
    "first_responder = ResponderWithRetries(\n",
    "    runnable=initial_answer_chain, validator=validator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1aadea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_question = \"Why is reflection useful in AI?\"\n",
    "# initial = first_responder.respond(\n",
    "#     {\"messages\": [HumanMessage(content=example_question)]}\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c7af31-b469-46fc-b441-0acb28515c7a",
   "metadata": {},
   "source": [
    "#### 3 Revision\n",
    "\n",
    "The second part of the actor is a revision step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2605fd8d-c663-446f-ba25-751190195749",
   "metadata": {},
   "outputs": [],
   "source": [
    "revise_instructions = \"\"\"Revise your previous answer using the new information.\n",
    "    - You should use the previous critique to add important information to your answer.\n",
    "        - You MUST include numerical citations in your revised answer to ensure it can be verified.\n",
    "        - Add a \"References\" section to the bottom of your answer (which does not count towards the word limit). In form of:\n",
    "            - [1] https://example.com\n",
    "            - [2] https://example.com\n",
    "    - You should use the previous critique to remove superfluous information from your answer and make SURE it is not more than 250 words.\n",
    "\"\"\"\n",
    "\n",
    "# Extend the initial answer schema to include references.\n",
    "# Forcing citation in the model encourages grounded responses\n",
    "class ReviseAnswer(AnswerQuestion):\n",
    "    \"\"\"Revise your original answer to your question. Provide an answer, reflection,\n",
    "\n",
    "    cite your reflection with references, and finally\n",
    "    add search queries to improve the answer.\"\"\"\n",
    "\n",
    "    references: list[str] = Field(\n",
    "        description=\"Citations motivating your updated answer.\"\n",
    "    )\n",
    "\n",
    "\n",
    "revision_chain = actor_prompt_template.partial(\n",
    "    first_instruction=revise_instructions,\n",
    "    function_name=ReviseAnswer.__name__,\n",
    ") | llms[1].bind_tools(tools=[ReviseAnswer])\n",
    "revision_validator = PydanticToolsParser(tools=[ReviseAnswer])\n",
    "\n",
    "revisor = ResponderWithRetries(\n",
    "    runnable=revision_chain, validator=revision_validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6fd51f17-c0b0-44b6-90e2-55a66cb8f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# revised = revisor.respond(\n",
    "#     {\n",
    "#         \"messages\": [\n",
    "#             HumanMessage(content=example_question),\n",
    "#             initial[\"messages\"],\n",
    "#             ToolMessage(\n",
    "#                 tool_call_id=initial[\"messages\"].tool_calls[0][\"id\"],\n",
    "#                 content=json.dumps(\n",
    "#                     tavily_tool.invoke(\n",
    "#                         {\n",
    "#                             \"query\": initial[\"messages\"].tool_calls[0][\"args\"][\n",
    "#                                 \"search_queries\"\n",
    "#                             ][0]\n",
    "#                         }\n",
    "#                     )\n",
    "#                 ),\n",
    "#             ),\n",
    "#         ]\n",
    "#     }\n",
    "# )\n",
    "# revised[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf86d9d",
   "metadata": {},
   "source": [
    "## Create Tool Node\n",
    "\n",
    "Next, create a node to execute the tool calls. While we give the LLMs different schema names (and use those for validation), we want them both to route to the same tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fccd6a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "def run_queries(search_queries: list[str], **kwargs):\n",
    "    \"\"\"Run the generated queries.\"\"\"\n",
    "    return search_tools[0].batch([{\"query\": query} for query in search_queries])\n",
    "\n",
    "\n",
    "def run_queries2(search_queries: list[str], **kwargs):\n",
    "    \"\"\"Run the generated queries.\"\"\"\n",
    "    return search_tools[1].batch([{\"query\": query} for query in search_queries])\n",
    "\n",
    "tool_node = ToolNode(\n",
    "    [\n",
    "        StructuredTool.from_function(run_queries, name=AnswerQuestion.__name__),\n",
    "        StructuredTool.from_function(run_queries2, name=ReviseAnswer.__name__),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e623a6c9-b69b-438c-9e6e-34a8883e0623",
   "metadata": {},
   "source": [
    "## Construct Graph\n",
    "\n",
    "\n",
    "Now we can wire all our components together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c57318f-a30c-4dbd-9b88-f2633e8cb3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"draft\", first_responder.respond)\n",
    "\n",
    "\n",
    "builder.add_node(\"execute_tools\", tool_node)\n",
    "builder.add_node(\"revise\", revisor.respond)\n",
    "# draft -> execute_tools\n",
    "builder.add_edge(\"draft\", \"execute_tools\")\n",
    "# execute_tools -> revise\n",
    "builder.add_edge(\"execute_tools\", \"revise\")\n",
    "\n",
    "# Define looping logic:\n",
    "def _get_num_iterations(state: list):\n",
    "    i = 0\n",
    "    for m in state[::-1]:\n",
    "        if m.type not in {\"tool\", \"ai\"}:\n",
    "            break\n",
    "        i += 1\n",
    "    return i\n",
    "\n",
    "def event_loop(state: list):\n",
    "    # in our case, we'll just stop after N plans\n",
    "    num_iterations = _get_num_iterations(state[\"messages\"])\n",
    "    if num_iterations > MAX_ITERATIONS:\n",
    "        return END\n",
    "    return \"execute_tools\"\n",
    "\n",
    "# revise -> execute_tools OR end\n",
    "builder.add_conditional_edges(\"revise\", event_loop, [\"execute_tools\", END])\n",
    "builder.add_edge(START, \"draft\")\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7541f82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2634a3ea-7423-4579-9f4e-390e439c3209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "明年最有发展的国家是？\n",
      "Step 1\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  AnswerQuestion (call_-9158280088861264363)\n",
      " Call ID: call_-9158280088861264363\n",
      "  Args:\n",
      "    answer: 预测明年最有发展的国家涉及多方面因素，包括经济政策、政治稳定性、科技创新、资源储备等。目前，一些国家如中国、印度、美国因其在这些领域的强劲表现而备受关注。中国和印度作为新兴市场，拥有庞大的人口基数和快速发展的经济；美国则凭借其科技创新和成熟的金融市场保持竞争力。然而，具体哪个国家将表现最佳，还需考虑全球经济环境、地缘政治变化等不确定因素。\n",
      "    reflection: {'missing': '缺乏具体数据和近期全球经济政治趋势分析，未能提供更精确的预测依据。', 'superfluous': '对国家的一般性描述过多，未能聚焦于具体的发展潜力和预测依据。'}\n",
      "    search_queries: ['2025年全球经济预测', '2025年地缘政治趋势', '2025年科技创新国家排名']\n",
      "Step 2\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: AnswerQuestion\n",
      "\n",
      "[[{\"url\": \"https://www.huxiu.com/article/3616892.html\", \"content\": \"IMF 2025年展望：全球经济将如何发展？-虎嗅网 虎嗅APP__虎嗅APP 公众号矩阵__公众号矩阵 我要投稿__我要投稿 资讯 24小时 源流 视频 专题/活动 妙投 虎嗅智库 IMF 2025年展望：全球经济将如何发展？ 培风客©关注 本文来自微信公众号：培风客 （ID：peifengke），作者：Odysseus，原文标题：《IMF 2025年展望 - 完美剧本和十字路口》，题图来自：AI生成 文章摘要 IMF 2025年全球经济展望：财政刺激退坡，货币政策顶上，通胀温和走低。   • 🌍 预测2025年全球经济风险增加，上行和下行风险并存   • 📉 通胀走低但预测困难，受基数效应和制造服务业背离影响   • 💼 重点关注美国赤字、中国财政政策和全球利率走势 这几天在IMF的年会上，我感觉就很割裂，在经济话题上本来IMF就比较看重财政，所以财政成为了很多公开和私下讨论的焦点。但另一方面，有无数关于气候和平等的话题。所以经常是刚听到说各个国家要恢复财政纪律，然后另一边就在说气候挑战需要更多资金和关注。我只能说气候和平等都是非常重要的问题，但可惜我一窍不通，所以我们今天讨论的是经济。 这里还有一个趣事，这次IMF坦诚在经济预测里面，其实并没有把中国的刺激考虑进去，他们觉得这是正确的做法，但觉得还需要一些时间观察效果。我朋友的说法就是，IMF半年开一次会，然后大家吭哧吭哧写了半年报告，结果距离发布前3周的时候，中国做一个大规模刺激，那要么重新写一遍170页的报告，要么就只能“还需要一点观察效果”。所以这里面关于中国和通胀的预测，就像他们在会上自己说的，没有完全反映最新的情况。 但我依然觉得这份经济展望很值得一读，因为它给出了一个经济的完美剧本。这种最理想的剧本往往可以很好地成为经济展望里面的基本假设。 在十年前，基本假设是最有可能成真的假设，而现在，基本假设可能是最不会实现的假设。因为正如IMF报告里面说的，剧本完美，但无奈干扰项太多了，而且干扰项看起来一个比一个真实。但就像前面说的，如果你在展望2025年，IMF的这个报告可以成为很好的基本假设。 简单来说，IMF对2025年的完美看法是，财政刺激退坡，货币政策顶上，产出缺口闭合，通胀温和走低，经济继续扩张。 然后这个情景有两个风险，一个上行机会，一个下行风险： 下行风险在于：1. 全球关税增加；2. 贸易政策不确定性增加；3. 美国税收不确定性；4. 欧盟和美国的移民问题；5. 全球金融市场不确定性。 上行机会在于：1. 中国的再平衡（更多的社会支出），2. 欧盟增加公共支出。 然后自然，大家一看就知道，这个下行风险看起来比上行风险真实多了，所以IMF的标题是： 政策转向，风险增加。 当然在线下讨论的时候，和我交流的大部分人都表示，2025年可能是上行和下行风险一起发生。因为大家也都知道，中国如果外需走弱，内需就会加码刺激。我相信中国的商品投资者这两天也会有这种内外走势开始扭转的感觉。 所以我简单分享一下IMF的看法，然后借着它的图讨论一下我自己的看法。一个经典的宏观分析，其实可以从利率出发去GDP再去通胀，也可以从通胀出发去利率再去GDP，此时此刻，通胀依然是全世界的关注焦点，所以和IMF一样，我们从通胀讨论起。 通胀：可能走低？ 大部分图给我的感觉都证明了通胀可能是持续的，但结论是通胀可能走低。 在所有经济预测中，我自己最不相信的就是通胀预测，因为每一次预测，都是长上面这样，“未来是平的”。 可偏偏通胀永远不是平的，它要么走高，要么走低。 所以通胀是一个最难预测也最好预测的东西，难在你几乎永远猜不准它的水平，但简单在你只需要拍脑袋选一个方向，它自己就有趋势性。 那么具体一点。 过去两年降低通胀没有牺牲太多GDP增长，我觉得有两个原因，IMF给的这个图非常准，确实很有水平： 1. 基数效应； 2. 服务业和制造业的背离。 基数效应意思是，商品价格前年50，去年100，今年100，通胀去年是100%，今年是0%，那么今年你什么都不用做，通胀就走低了100%。当然，从这个报告里我学会了更文艺的表达方法，Sacrifice Ratio（每降低1%的通胀，需要降低多少GDP），可以看到2022年到2024年Q1，这个比率非常低，就是上面说的这个道理，联储只需要坚定加息，遏制商品价格继续走高的倾向，基数效应可以帮助联储完成大部分工作。 制造业和服务业的背离说的是，目前商品通胀已经降低到疫情前的水平，而服务业没有，发达国家服务业更多，新兴市场国家制造业更多，所以发达国家受到的压力更小，而新兴市场国家受到的压力更大。 所以过去两年对于发达国家来说，或者说对于美国来说，通胀走低是一个大家都开心的事情，因为制造业PMI一直在50以下，而占经济大头的服务业还在扩张。那么此时此刻，改革进入了深水区，如果要继续压制服务业通胀，就会造成更多的失业和GDP的走低。 利率：从财政到货币的转化 那么自然，大家就会思考如何更加圆润地完成这个工作。可以说想法也很多，我们看到过的有： 鸵鸟法：提高通胀目标，只要我的目标足够灵活，我就不会完不成目标； 古典派：祖宗之法不可变，1995年说的2%的通胀目标就一定要实现。 不一而足。 到目前为止，我们看到的是，货币政策已经在全球范围内开始转向。 这种转向已经慢慢带来了信贷需求的恢复，就是之前说的，4%的长端利率对于很多公司来说都是可以考虑的一个借贷成本。所以问题现在并不是在大公司，而是在那些没法发债，更多依靠贷款的小公司，他们的能力更差，但面对的利率更高。 而发达国家的财政支出可能会慢慢减少。 与此同时，可以看到随着降息的发生，新兴市场国家可能会做更多的财政刺激。 这里我想稍微停一下说一个另外的问题，如果说2019年说财政带来通胀，大家会觉得天方夜谭，那么此时我觉得不会有太多人怀疑这个问题。所以发达市场和新兴市场财政的转变可能会带来通胀预期的扭转。而其实很多时候，我觉得投资是个世界观的问题，财政就是一个例子。 发达国家拥有比新兴市场更多的财政空间，这个事情要看你从什么角度看。比方说发达国家可以有80%的公共债务/GDP比率，而新兴市场国家可能只能有50%，甚至最穷的新兴市场国家可能更少。 从金融市场的角度来说，这很合理，因为发达国家市场更完善，制度更加健全，所以拥有更高的比例。但就像大家诟病银行总是给不缺水的人送水，发展中国家其实比发达国家需要更高的财政支持。因为他们更需要发展。这个世界发展的权利到底应不应该是公平的，是一个极深的讨论。我始终觉得，人类没有到马放南山的时候，在危机中的人类应该拥有公平的发展权力。 所以在理想情况下，我们会看到一个发达国家政府逐渐收回自己手，通过降息和减税给市场主体更多支持的过程（特朗普的主张绝对不是无源之水），而这个过程不说通胀怎么走，至少先行指标一进一出，总体还是平衡的。 但就像前面说的，这个假设面对无数可能的挑战，地缘政治（战争有时候是有自己的惯性的，想想当年美国撤出越战、撤出阿富汗用了多少年），贸易摩擦，IMF直接用了冷战时候的贸易走向对比今天。 战时经济和市场经济的思路是迥异的。 经济：如果一切顺利，它可能会是平的 我相信如果大家看了上面这些图，就知道我们现在的世界面对多少挑战。如果一切都符合预期，通胀温和走低，货币宽松，财政退坡，重振财政纪律，那么我们会有一个平缓的GDP增长。 IMF的题目是：Stable Growth amid Continuing Disinflation。 就像上面说的，如果一切顺利，是一个很大的假设，所以我想聊两个其他问题： 美国的赤字 首先我不相信中美这样体量的国家，会因为赤字问题遭遇灭顶之灾。我从来不觉得赤字是个问题，可能这也是美国从来不待见IMF的原因之一。 但赤字还是要有一个度，或者说，你不能无止境增加下去，比方说最新的美国利息支出已经超过了国防支出，按照IMF的说法，这样下去到2030年美国一半的赤字都在为自己的利息融资。那么就有一个说法叫做，怎么控制赤字。 特朗普有很多可能的财长人选，其中看起来最靠谱的一位是贝森特，他的一个说法就是要尽可能把赤字率拉回到3%，所以第一个问题就是，怎么降低赤字？ 无论是从财政的机制上，还是从历史上，美国赤字降低很少可以直接砍掉支出，因为美国财政里面很多项目都是没得谈的，都是固定的，然后可以谈的部分，没记错的话，你要么要和二十几个部门谈判，每个部门降低几个亿美金，等你干完这事情基本上得罪了所有人还起不到效果，要么你要去降低军费支出，这事情的难度大概相当于你做一个会计去阿富汗查账。 所以美国降低赤字一般都是通过GDP增长完成的，就是通过GDP增长来增加税源。就是上图里面画的。收入增长了，税源增加了，那么赤字就降低了。 所以回到今天，其实你会发现特朗普包括贝森特他们的说法是有逻辑的，就是现在这个赤字规模，要么有一个大萧条，物价重新回去2019年的水平，跌30%，然后赤字还有点可能性回来，如果不能承受一个萧条，那么要整理赤字问题，就必须让经济恢复，让GDP跑得比通胀更快提高实际收入才可以了。而且这里还有一个细节问题，税源增加和税收增加之间，还隔着一个收税的流程。对于美国来说，中产阶级和海外国家是更好征税的人群。确实在纸面上可以对富人征税，但收不到不也是一句空话...... 换句话说，还是之前那个结论，一个萧条或者一个复苏都可以解决美国的问题。短期因为选举和降息萧条的风险多多少少有一点，中长期看肯定还是看复苏的。 中国的问题 在2022~2023年，有无数投资逻辑底层都是，做多美国的实际利率，因为财政和移民都有可能增加美国的利率水平。当然这里面黄金可以说本来是所有人众望所归的空配品种，但就像之前说的，大宗商品，我可以保证没有任何一个品种可以只从宏观上去交易，黄金、铜、石油是三个最大的品种也是最被金融和宏观投资者青睐的品种，但如果搞不清楚这些东西的交易对手和交易机构，只从宏观数据出发去做交易，在2019年之前可以，在2020年之后就很难。而且以后只怕一直会这样。 这个硬币的另一面就是做空中国的实际利率，无论是debt-deflation，还是所谓的人口问题。这两个东西放在一起，就是人民币汇率的压力，多有色空黑色的交易，包括多EMxC空中国的交易。 所以某种意义上来说，货币政策在过去两年，其实是财政政策的一个影子，或者说财政才是决定货币的项目。美国做了财政刺激，通胀比较高，所以货币政策需要去加息，但加了息实际利率还是不高。中国没有做财政刺激，通胀非常低，所以需要货币政策去降息，但降息了实际利率还是偏低。 所以中国的财政问题就是一切的核心，而中国一向以来都是，外需不足的时候，内需才顶上，只要出口还不错，那么政策就不着急。我觉得我们看到的中国财政转向，和过去20年的范式没有太多不同。 最后我想说，在2025年，我们很有可能看到的是上行和下行风险一起出现，关税增加，中国内需刺激，全球贸易受到冲击，但中国和欧洲的投资可能增加，全球金融市场不稳定性增加，而利率却已经走低。这种复合的模式，有可能给2025年带来很多结构性的机会。 本内容为作者独立观点，不代表虎嗅立场。未经允许不得转载，授权事宜请联系hezuo@huxiu.com 如对本稿件有异议或投诉，请联系tougao@huxiu.com 正在改变与想要改变世界的人，都在 虎嗅APP Copyright ©  虎嗅网 京ICP备12013432号-1       京公网安备 11010502037938号\"}, {\"url\": \"https://xueqiu.com/6426348328/315557975\", \"content\": \"一、全球经济形势：经济增速平稳，美联储降息周期开启. 2025年全球经济增速持平，美国经济仍具韧性。2025年，imf预测全球gdp增速为3.2%，和今年持平。\"}, {\"url\": \"https://caijing.chinadaily.com.cn/a/202410/23/WS67182bb8a310b59111d9f50d.html\", \"content\": \"当地时间10月22日，国际货币基金组织（imf）发布最新一期《世界经济展望报告》。报告称，在通货紧缩过程中，全球经济保持了异常强劲的韧性，预计2024年和2025年全球经济增速为3.2% 。\"}, {\"url\": \"https://user.guancha.cn/main/content?id=1347132\", \"content\": \"整体来看，2025年全球经济在挑战与机遇并存中前行，需加强国际合作，共同应对风险，推动全球经济持续健康发展。 全球经济发展趋势如何？ 今天，走出去智库（CGGT）刊发经济学人智库(EIU)报告的重点内容，供关注全球化发展的读者参阅。\"}, {\"url\": \"https://www.imf.org/zh/Publications/WEO/Issues/2024/10/22/world-economic-outlook-october-2024\", \"content\": \"全球经济增长预计将保持稳定，但也乏善可陈。尽管如此，在表面之下，一些预测值自2024年4月以来已得到了重要调整。其中，美国的预测值被上调，这抵消了其他发达经济体（特别是欧洲最大国家）预测值的下调。同样，在新兴市场和发展中经济体，多种因素导致了中东、中亚以及撒哈拉以南非洲\"}], [{\"url\": \"https://cn.weforum.org/stories/2024/09/geopolitics-inflation-central-banks-cn/\", \"content\": \"一项新的调查显示，地缘政治问题已经超过通胀，成为各国央行和主权财富基金的首要风险因素。 ... 《2024年全球主权资产管理研究》（Global Sovereign Asset Management Study 2024）中概述的趋势表明，在当前全球地缘政治 ... 展望未来十年，86%的受访者认为地缘政治分裂\"}, {\"url\": \"https://news.qq.com/rain/a/20241118A089MD00\", \"content\": \"萨米尔·萨兰预测，2025年全球最大的地缘政治挑战之一将是美国与中国之间日益加剧的战略竞争。 自从特朗普政府以来，关于贸易、技术、军事等\"}, {\"url\": \"https://baijiahao.baidu.com/s?id=1815026036348879773\", \"content\": \"有人说，2025年注定是个多事之秋。全球的地缘政治挑战，像是一颗颗定时炸弹，随时可能引爆。无论是国际秩序的失衡，还是主权争端的升级，亦或是贸易保护主义的抬头、人工智能的集中化、新能源领域的博弈，每一个问题都关乎全球未来的走向。\"}, {\"url\": \"https://www.rfi.fr/cn/国际报道/20241127-全球4大地缘政治热点怎拆弹-2025看川普\", \"content\": \"全球4大地缘政治热点怎拆弹 2025看川普 （法新社巴黎27日电） 随着中东及俄乌战火延烧，亚洲局势也日益紧张，未来一年这些都将考验着美国候任\"}, {\"url\": \"https://news.qq.com/rain/a/20241104A0720X00\", \"content\": \"印度学者文章：2025年全球面临五大地缘政治挑战_腾讯新闻 印度学者文章：2025年全球面临五大地缘政治挑战 国际先驱导报2024-11-04 17:32 全文1533字，阅读约需5分钟，帮我划重点 划重点 012025年全球将面临五大地缘政治挑战，包括推进安全、理解主权、恢复经济全球化、保持创新的去中心化和新能源用于气候行动。 02由于全球合作处于低谷，领导者需要寻找脆弱的共识，以应对日益加剧的冲突和分歧。 03同时，领导者需要重新思考全球贸易体系，确保贸易长期利益的同时，在新伙伴之间协商新的安排。 04此外，保持创新和研究的精简、去中心化和竞争力，以及确保价值创造和创新的场所变得更加包容，将是领导者面临的挑战之一。 05最后，如何有效部署资本到能够发挥最大作用的部门和地区，以应对全球变暖等环境问题，将是2025年领导者需要解决的问题。 以上内容由腾讯混元大模型生成，仅供参考 如果2024是大选年，那么2025将是问题年。未来一年，领导者需要回答哪些最紧迫的地缘政治问题？以下是2025年的五大问题： 一、如何在四分五裂的全球秩序内推进安全？ 全球合作处于低谷，冲突不断加剧升级。最近的事实证明，世贸组织和联合国这些传统的领导者和机构无力达成广泛的全球共识或者充当解决争端的平台。 2024年最具争议的两场冲突——俄罗斯正在乌克兰持续进行的战争以及以色列和哈马斯在加沙的冲突——源自长期存在的摩擦。这些冲突突然激化，表明全球安全秩序太过支离破碎，无法维持或达成和平。 在这种背景下，当普世价值观无法坚持、现有秩序日益瓦解，领导者将被迫承认自身影响力的局限以及各种联盟的制约。 领导者将不得不问：有什么办法跨越分歧，防止进一步冲突？领导者能否接受对自身权力的更多限制，承担起维和的重任？ 二、在当代世界如何理解主权？ 基于规则的秩序这一理念自1945年以来历经艰辛才得以维系。如今，这个理念与实现的距离比80年来的任何时候都更遥远。没有共同的准则、强有力的机制和对国际法的承诺，就难以塑造稳定和平的环境。 虽然军队越过有形边界是对主权的悍然侵犯，但反常的经济措施、对政治制度的操纵，以及对市场准入、贸易安排和支付系统使用的管控可能违反联合国宪章，并且可能侵犯主权的最重要方面。 近几十年来，人们认为，各国为建立“有凝聚力的”全球秩序，必不可少要在某些政策上把主权和独立决定的能力让给全球治理机构。现在，即使是全球秩序的捍卫者也认为，在国家主权得不到尊重的世界，规则无法设计或执行。 因此，2025年领导者会问：在加强为民众提供安全的跨国架构的同时，国家的独立能否得到维护和振兴？ 三、如何恢复（并重新设计）贸易和经济全球化？ 贸易的黄金时代似乎即将结束。2023年，货物贸易萎缩约2%，除全球衰退期以外，比本世纪的其他任何时候都高。与此同时，由于国内政治环境和全球价值链被扭曲，保护主义的产业政策卷土重来，因此必须重新思考全球贸易体系。 被保护主义力量拆散的供应链可能导致全球经济体系效率低下，从而带来新的通胀压力。更糟的是，终点可能是一种“封闭式的全球化”，即利润和发展只限于选中的参与者。 因此，2025年领导者需要提出问题：我们能否学会在确保贸易长期利益的同时，在新伙伴之间协商新的安排？我们将如何从贸易中创造新的收益，我们能否加倍努力以更加公平地分享贸易收益？ 四、我们能否保持创新的去中心化？ 人工智能和其他先进技术对社会和经济的影响才刚刚开始为人所知。过去几十年的其他技术发展使之前缺乏联系的地区有机会赶上全球前沿。人工智能可能会以不同方式影响不平等状况：它似乎偏向算法所有者、数据所有者、资本所有者和主宰处理能力的场所。如果需要利用人工智能建造更多人工智能，那么有充分理由假设，对就业和增长至关重要的技术创新的去中心化可能即将终结。这种趋势将严重限制新兴经济体创造更多财富的能力。 因此，领导者需要问：我们怎样才能保持创新和研究的精简、去中心化和竞争力？我们能否确保价值创造和创新的场所变得更加包容而不是相反？如何设计全球监管机构，使之跟上变化的速度，从而公平地分配技术带来的益处？ 五、新能源能否用于气候行动？ 2023年，全球首次突破《巴黎协定》设定的1.5摄氏度的平均升温阈值，其影响清晰可见，包括强迫迁移、生物多样性丧失、营养不良和更多领域的失控。这些后果正在产生不公平的影响，那些对全球变暖贡献最小的群体受到的影响往往最大。这种差异凸显许多全球框架的失败，这些框架本来旨在动员资金以控制排放并帮助适应气候变化。 领导者会问，也会被问：如何才能把充足的资本有效地部署到能够发挥最大作用的部门和地区？ 2025年，世界各地的领导者将不得不寻找五大问题的答案。在不理性、不一致以及有多种声音存在的情况下，找到脆弱的共识比以往任何时候都重要。 ▲这是2024年3月20日在瑞士日内瓦拍摄的联合国万国宫。（新华社记者 连漪 摄） 本文由世界经济论坛网站11月1日发表，原题为《2025年的五大地缘政治问题》，作者是印度观察家研究基金会主席萨米尔·萨兰。 查看原图 167K\"}], [{\"url\": \"https://www.huxiu.com/article/3788007.html\", \"content\": \"2025年科技趋势：实时ai、企业重塑、医疗革新。 ... 在争夺ai主导地位的竞赛中，算力已经成为关键的国家基础设施。 ... 如此令人瞩目的疗效，连同新药的商业成功，正激发着一波聚焦重大疾病的新生物科技创新浪潮。\"}, {\"url\": \"https://www.wipo.int/zh/web/global-innovation-index/index\", \"content\": \"2024年全球创新指数（gii）对2024年全球最具创新力的经济体进行了排名,共涉及133个经济体，并揭晓了全球领先的科技创新集群。它还揭示了如何通过社会企业家精神来促进创新，从而产生惠及世界各地所有人的社会影响。\"}, {\"url\": \"https://news.un.org/zh/story/2024/09/1131876\", \"content\": \"世界知识产权组织周四发布的《2024年全球创新指数》显示，瑞士、瑞典、美国、新加坡和英国是世界上最具创新力的经济体，中国排名第11位，仍然是全球创新指数排名前30位中 唯一 ... 联合国秘书长古特雷斯周二在中国上海表示，人工智能能力集中在几个国家\"}, {\"url\": \"https://www.news.cn/politics/2023-11/22/c_1129987064.htm\", \"content\": \"国家创新指数是反映国家综合创新能力的重要指标。11月21日，中国科学技术发展战略研究院发布的《国家创新指数报告2022—2023》（以下简称\\\"报告\\\"）显示：全球创新格局保持亚美欧三足鼎立态势，科技创新中心东移趋势更加显著，中国创新能力综合排名上升至世界第10位，向创新型国家前列\"}, {\"url\": \"https://www.wipo.int/pressroom/zh/articles/2023/article_0011.html\", \"content\": \"根据产权组织全球创新指数（gii），瑞士、瑞典、美利坚合众国、联合王国和新加坡是2023年全球最具创新力的经济体，而一批中等收入经济体成为过去十年来排名上升最快的国家。 根据产权组织全球创新指数（gii），瑞士、瑞典、美利坚合众国、联合王国和\"}]]\n",
      "Step 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  ReviseAnswer (ReviseAnswer:1)\n",
      " Call ID: ReviseAnswer:1\n",
      "  Args:\n",
      "    answer: 明年最有发展潜力的国家取决于多种因素，包括经济政策、科技创新、资源储备等。据IMF预测，2025年全球经济增长预计将保持稳定，其中美国因科技创新和货币政策的成熟而保持竞争力[1]。中国和印度由于其庞大的人口基数和经济增长速度，也显示出巨大的发展潜力[2]。同时，全球创新指数显示，瑞士、瑞典、美国、新加坡和英国等国家在科技创新方面排名靠前[3]。然而，地缘政治挑战如美国与中国之间的竞争，可能对全球经济产生影响[4]。因此，评估一个国家明年发展潜力时，需综合考虑经济、科技、政治等多方面因素。\n",
      "    references: ['https://xueqiu.com/6426348328/315557975', 'https://baijiahao.baidu.com/s?id=1815026036348879773', 'https://www.wipo.int/zh/web/global-innovation-index/index', 'https://news.qq.com/rain/a/20241118A089MD00']\n",
      "    reflection: {'missing': '原答案缺少具体的预测数据和排名信息，未能提供明确的国家名单和预测依据。', 'superfluous': '对一些国家的具体经济政策描述过于笼统，没有针对性。'}\n",
      "    search_queries: ['2025年全球经济预测', '2025年科技创新趋势', '全球政治稳定性对经济的影响']\n",
      "Step 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: ReviseAnswer\n",
      "\n",
      "[[{\"url\": \"https://www.huxiu.com/article/3616892.html\", \"content\": \"IMF 2025年展望：全球经济将如何发展？-虎嗅网 虎嗅APP__虎嗅APP 公众号矩阵__公众号矩阵 我要投稿__我要投稿 资讯 24小时 源流 视频 专题/活动 妙投 虎嗅智库 IMF 2025年展望：全球经济将如何发展？ 培风客©关注 本文来自微信公众号：培风客 （ID：peifengke），作者：Odysseus，原文标题：《IMF 2025年展望 - 完美剧本和十字路口》，题图来自：AI生成 文章摘要 IMF 2025年全球经济展望：财政刺激退坡，货币政策顶上，通胀温和走低。   • 🌍 预测2025年全球经济风险增加，上行和下行风险并存   • 📉 通胀走低但预测困难，受基数效应和制造服务业背离影响   • 💼 重点关注美国赤字、中国财政政策和全球利率走势 这几天在IMF的年会上，我感觉就很割裂，在经济话题上本来IMF就比较看重财政，所以财政成为了很多公开和私下讨论的焦点。但另一方面，有无数关于气候和平等的话题。所以经常是刚听到说各个国家要恢复财政纪律，然后另一边就在说气候挑战需要更多资金和关注。我只能说气候和平等都是非常重要的问题，但可惜我一窍不通，所以我们今天讨论的是经济。 这里还有一个趣事，这次IMF坦诚在经济预测里面，其实并没有把中国的刺激考虑进去，他们觉得这是正确的做法，但觉得还需要一些时间观察效果。我朋友的说法就是，IMF半年开一次会，然后大家吭哧吭哧写了半年报告，结果距离发布前3周的时候，中国做一个大规模刺激，那要么重新写一遍170页的报告，要么就只能“还需要一点观察效果”。所以这里面关于中国和通胀的预测，就像他们在会上自己说的，没有完全反映最新的情况。 但我依然觉得这份经济展望很值得一读，因为它给出了一个经济的完美剧本。这种最理想的剧本往往可以很好地成为经济展望里面的基本假设。 在十年前，基本假设是最有可能成真的假设，而现在，基本假设可能是最不会实现的假设。因为正如IMF报告里面说的，剧本完美，但无奈干扰项太多了，而且干扰项看起来一个比一个真实。但就像前面说的，如果你在展望2025年，IMF的这个报告可以成为很好的基本假设。 简单来说，IMF对2025年的完美看法是，财政刺激退坡，货币政策顶上，产出缺口闭合，通胀温和走低，经济继续扩张。 然后这个情景有两个风险，一个上行机会，一个下行风险： 下行风险在于：1. 全球关税增加；2. 贸易政策不确定性增加；3. 美国税收不确定性；4. 欧盟和美国的移民问题；5. 全球金融市场不确定性。 上行机会在于：1. 中国的再平衡（更多的社会支出），2. 欧盟增加公共支出。 然后自然，大家一看就知道，这个下行风险看起来比上行风险真实多了，所以IMF的标题是： 政策转向，风险增加。 当然在线下讨论的时候，和我交流的大部分人都表示，2025年可能是上行和下行风险一起发生。因为大家也都知道，中国如果外需走弱，内需就会加码刺激。我相信中国的商品投资者这两天也会有这种内外走势开始扭转的感觉。 所以我简单分享一下IMF的看法，然后借着它的图讨论一下我自己的看法。一个经典的宏观分析，其实可以从利率出发去GDP再去通胀，也可以从通胀出发去利率再去GDP，此时此刻，通胀依然是全世界的关注焦点，所以和IMF一样，我们从通胀讨论起。 通胀：可能走低？ 大部分图给我的感觉都证明了通胀可能是持续的，但结论是通胀可能走低。 在所有经济预测中，我自己最不相信的就是通胀预测，因为每一次预测，都是长上面这样，“未来是平的”。 可偏偏通胀永远不是平的，它要么走高，要么走低。 所以通胀是一个最难预测也最好预测的东西，难在你几乎永远猜不准它的水平，但简单在你只需要拍脑袋选一个方向，它自己就有趋势性。 那么具体一点。 过去两年降低通胀没有牺牲太多GDP增长，我觉得有两个原因，IMF给的这个图非常准，确实很有水平： 1. 基数效应； 2. 服务业和制造业的背离。 基数效应意思是，商品价格前年50，去年100，今年100，通胀去年是100%，今年是0%，那么今年你什么都不用做，通胀就走低了100%。当然，从这个报告里我学会了更文艺的表达方法，Sacrifice Ratio（每降低1%的通胀，需要降低多少GDP），可以看到2022年到2024年Q1，这个比率非常低，就是上面说的这个道理，联储只需要坚定加息，遏制商品价格继续走高的倾向，基数效应可以帮助联储完成大部分工作。 制造业和服务业的背离说的是，目前商品通胀已经降低到疫情前的水平，而服务业没有，发达国家服务业更多，新兴市场国家制造业更多，所以发达国家受到的压力更小，而新兴市场国家受到的压力更大。 所以过去两年对于发达国家来说，或者说对于美国来说，通胀走低是一个大家都开心的事情，因为制造业PMI一直在50以下，而占经济大头的服务业还在扩张。那么此时此刻，改革进入了深水区，如果要继续压制服务业通胀，就会造成更多的失业和GDP的走低。 利率：从财政到货币的转化 那么自然，大家就会思考如何更加圆润地完成这个工作。可以说想法也很多，我们看到过的有： 鸵鸟法：提高通胀目标，只要我的目标足够灵活，我就不会完不成目标； 古典派：祖宗之法不可变，1995年说的2%的通胀目标就一定要实现。 不一而足。 到目前为止，我们看到的是，货币政策已经在全球范围内开始转向。 这种转向已经慢慢带来了信贷需求的恢复，就是之前说的，4%的长端利率对于很多公司来说都是可以考虑的一个借贷成本。所以问题现在并不是在大公司，而是在那些没法发债，更多依靠贷款的小公司，他们的能力更差，但面对的利率更高。 而发达国家的财政支出可能会慢慢减少。 与此同时，可以看到随着降息的发生，新兴市场国家可能会做更多的财政刺激。 这里我想稍微停一下说一个另外的问题，如果说2019年说财政带来通胀，大家会觉得天方夜谭，那么此时我觉得不会有太多人怀疑这个问题。所以发达市场和新兴市场财政的转变可能会带来通胀预期的扭转。而其实很多时候，我觉得投资是个世界观的问题，财政就是一个例子。 发达国家拥有比新兴市场更多的财政空间，这个事情要看你从什么角度看。比方说发达国家可以有80%的公共债务/GDP比率，而新兴市场国家可能只能有50%，甚至最穷的新兴市场国家可能更少。 从金融市场的角度来说，这很合理，因为发达国家市场更完善，制度更加健全，所以拥有更高的比例。但就像大家诟病银行总是给不缺水的人送水，发展中国家其实比发达国家需要更高的财政支持。因为他们更需要发展。这个世界发展的权利到底应不应该是公平的，是一个极深的讨论。我始终觉得，人类没有到马放南山的时候，在危机中的人类应该拥有公平的发展权力。 所以在理想情况下，我们会看到一个发达国家政府逐渐收回自己手，通过降息和减税给市场主体更多支持的过程（特朗普的主张绝对不是无源之水），而这个过程不说通胀怎么走，至少先行指标一进一出，总体还是平衡的。 但就像前面说的，这个假设面对无数可能的挑战，地缘政治（战争有时候是有自己的惯性的，想想当年美国撤出越战、撤出阿富汗用了多少年），贸易摩擦，IMF直接用了冷战时候的贸易走向对比今天。 战时经济和市场经济的思路是迥异的。 经济：如果一切顺利，它可能会是平的 我相信如果大家看了上面这些图，就知道我们现在的世界面对多少挑战。如果一切都符合预期，通胀温和走低，货币宽松，财政退坡，重振财政纪律，那么我们会有一个平缓的GDP增长。 IMF的题目是：Stable Growth amid Continuing Disinflation。 就像上面说的，如果一切顺利，是一个很大的假设，所以我想聊两个其他问题： 美国的赤字 首先我不相信中美这样体量的国家，会因为赤字问题遭遇灭顶之灾。我从来不觉得赤字是个问题，可能这也是美国从来不待见IMF的原因之一。 但赤字还是要有一个度，或者说，你不能无止境增加下去，比方说最新的美国利息支出已经超过了国防支出，按照IMF的说法，这样下去到2030年美国一半的赤字都在为自己的利息融资。那么就有一个说法叫做，怎么控制赤字。 特朗普有很多可能的财长人选，其中看起来最靠谱的一位是贝森特，他的一个说法就是要尽可能把赤字率拉回到3%，所以第一个问题就是，怎么降低赤字？ 无论是从财政的机制上，还是从历史上，美国赤字降低很少可以直接砍掉支出，因为美国财政里面很多项目都是没得谈的，都是固定的，然后可以谈的部分，没记错的话，你要么要和二十几个部门谈判，每个部门降低几个亿美金，等你干完这事情基本上得罪了所有人还起不到效果，要么你要去降低军费支出，这事情的难度大概相当于你做一个会计去阿富汗查账。 所以美国降低赤字一般都是通过GDP增长完成的，就是通过GDP增长来增加税源。就是上图里面画的。收入增长了，税源增加了，那么赤字就降低了。 所以回到今天，其实你会发现特朗普包括贝森特他们的说法是有逻辑的，就是现在这个赤字规模，要么有一个大萧条，物价重新回去2019年的水平，跌30%，然后赤字还有点可能性回来，如果不能承受一个萧条，那么要整理赤字问题，就必须让经济恢复，让GDP跑得比通胀更快提高实际收入才可以了。而且这里还有一个细节问题，税源增加和税收增加之间，还隔着一个收税的流程。对于美国来说，中产阶级和海外国家是更好征税的人群。确实在纸面上可以对富人征税，但收不到不也是一句空话...... 换句话说，还是之前那个结论，一个萧条或者一个复苏都可以解决美国的问题。短期因为选举和降息萧条的风险多多少少有一点，中长期看肯定还是看复苏的。 中国的问题 在2022~2023年，有无数投资逻辑底层都是，做多美国的实际利率，因为财政和移民都有可能增加美国的利率水平。当然这里面黄金可以说本来是所有人众望所归的空配品种，但就像之前说的，大宗商品，我可以保证没有任何一个品种可以只从宏观上去交易，黄金、铜、石油是三个最大的品种也是最被金融和宏观投资者青睐的品种，但如果搞不清楚这些东西的交易对手和交易机构，只从宏观数据出发去做交易，在2019年之前可以，在2020年之后就很难。而且以后只怕一直会这样。 这个硬币的另一面就是做空中国的实际利率，无论是debt-deflation，还是所谓的人口问题。这两个东西放在一起，就是人民币汇率的压力，多有色空黑色的交易，包括多EMxC空中国的交易。 所以某种意义上来说，货币政策在过去两年，其实是财政政策的一个影子，或者说财政才是决定货币的项目。美国做了财政刺激，通胀比较高，所以货币政策需要去加息，但加了息实际利率还是不高。中国没有做财政刺激，通胀非常低，所以需要货币政策去降息，但降息了实际利率还是偏低。 所以中国的财政问题就是一切的核心，而中国一向以来都是，外需不足的时候，内需才顶上，只要出口还不错，那么政策就不着急。我觉得我们看到的中国财政转向，和过去20年的范式没有太多不同。 最后我想说，在2025年，我们很有可能看到的是上行和下行风险一起出现，关税增加，中国内需刺激，全球贸易受到冲击，但中国和欧洲的投资可能增加，全球金融市场不稳定性增加，而利率却已经走低。这种复合的模式，有可能给2025年带来很多结构性的机会。 本内容为作者独立观点，不代表虎嗅立场。未经允许不得转载，授权事宜请联系hezuo@huxiu.com 如对本稿件有异议或投诉，请联系tougao@huxiu.com 正在改变与想要改变世界的人，都在 虎嗅APP Copyright ©  虎嗅网 京ICP备12013432号-1       京公网安备 11010502037938号\"}, {\"url\": \"https://xueqiu.com/6426348328/315557975\", \"content\": \"一、全球经济形势：经济增速平稳，美联储降息周期开启. 2025年全球经济增速持平，美国经济仍具韧性。2025年，imf预测全球gdp增速为3.2%，和今年持平。\"}, {\"url\": \"https://caijing.chinadaily.com.cn/a/202410/23/WS67182bb8a310b59111d9f50d.html\", \"content\": \"当地时间10月22日，国际货币基金组织（imf）发布最新一期《世界经济展望报告》。报告称，在通货紧缩过程中，全球经济保持了异常强劲的韧性，预计2024年和2025年全球经济增速为3.2% 。\"}, {\"url\": \"https://user.guancha.cn/main/content?id=1347132\", \"content\": \"整体来看，2025年全球经济在挑战与机遇并存中前行，需加强国际合作，共同应对风险，推动全球经济持续健康发展。 全球经济发展趋势如何？ 今天，走出去智库（CGGT）刊发经济学人智库(EIU)报告的重点内容，供关注全球化发展的读者参阅。\"}, {\"url\": \"https://www.imf.org/zh/Publications/WEO/Issues/2024/10/22/world-economic-outlook-october-2024\", \"content\": \"全球经济增长预计将保持稳定，但也乏善可陈。尽管如此，在表面之下，一些预测值自2024年4月以来已得到了重要调整。其中，美国的预测值被上调，这抵消了其他发达经济体（特别是欧洲最大国家）预测值的下调。同样，在新兴市场和发展中经济体，多种因素导致了中东、中亚以及撒哈拉以南非洲\"}], [{\"url\": \"https://www.huxiu.com/article/3788007.html\", \"content\": \"2025年科技趋势：实时ai、企业重塑、医疗革新。实时ai协作颠覆创意流程，推动新应用。ai助力企业服务转型，提升效率和竞争力。ai赋能医疗创新，优化健康管理和服务。\"}, {\"url\": \"https://www.mittrchina.com/news/detail/13959\", \"content\": \"最近，CB Insights 发布了《2025 年科技趋势研究报告》，揭示了九项可能在未来 5 至 10 年内甚至更长时间里，深刻改变生活、工作和社会的科技创新。 这些技术不仅代表了前沿科技的发展趋势，也极可能成为未来商业竞争的核心。\"}, {\"url\": \"https://news.qq.com/rain/a/20241029A07KTL00\", \"content\": \"最近，CB Insights 发布了《2025 年科技趋势研究报告》，揭示了九项可能在未来 5 至 10 年内甚至更长时间里，深刻改变生活、工作和社会的科技创新\"}, {\"url\": \"https://finance.sina.com.cn/money/fund/fundzmt/2024-12-03/doc-incyezvp1417866.shtml\", \"content\": \"2025年值得关注的10大技术趋势|人工智能_新浪财经_新浪网 新浪首页 新闻 体育 财经 娱乐 科技 博客 图片 专栏 更多 汽车 教育 时尚 女性 星座 健康 房产历史视频收藏育儿读书 佛学游戏旅游邮箱导航 移动客户端 新浪微博 新浪新闻 新浪财经 新浪体育 新浪众测 新浪博客 新浪视频 新浪游戏 天气通 我的收藏 注册 登录 基金 > 正文 2025年值得关注的10大技术趋势 2025年值得关注的10大技术趋势 2024年12月03日 21:49 投资家 新浪财经APP 缩小字体 放大字体 收藏 微博 微信 分享 腾讯QQ QQ空间 来源：投资家 科学技术正以前所未有的速度发展，重塑行业，改变人们的生活和工作方式。到2025年，人们可以期待突破性的进步，这些进步将推动创新、提高效率并创造新的机会。 从人工智能到绿色科技，以下是2025年值得关注的10大科技趋势: 1.人工智能无处不在 人工智能不再关乎未来，而是当代的。到2025年，人工智能将不可避免地深入到医疗卫生、教育和交通等各个领域。 人工智能工具将变得更加智能，为企业和个人提供个性化的解决方案。期待看到人工智能帮助诊断疾病，优化供应链，甚至更大规模地为自动驾驶汽车提供动力。 2.量子计算的出现 量子计算将解决经典计算机无法解决的问题。量子技术将在2025年取得进展，并将在密码学、药物研发和气候建模等领域取得突破。 像谷歌、IBM以及量子空间初创公司这样的公司正在竞相使他们的量子计算机变得可访问和有影响力。 3.5G及以上 5G已经对连接进行了彻底检查，并将在2025年前深化。更流畅、更快的速度，更低的时延水平，甚至更大的覆盖范围，将开启AR（增强现实）、VR（虚拟现实）和IoT（物联网）的新梦想。 此外，对6G技术的研究也将开始成形，并承诺一个日益互联的未来。 4.绿色技术和可持续发展 随着世界继续致力于建设可持续发展的世界，绿色技术将在2025年占据主导地位。期待可再生能源系统的进步，如更高效的光伏电池和风力涡轮机，以及碳捕获和存储方面的创新。 绿色技术也将影响产品的制造，企业正在采用循环经济，通过创新的解决方案减少浪费。 5.元宇宙的崛起 事实上，元宇宙正在快速转型，到2025年，在VR、AR和触觉技术的推动下，将提供更真实的体验。这是一个沉浸式的共享数字空间。 它将影响游戏、教育和远程工作行业，因为企业将找到在虚拟环境中与用户互动的方法。 6.超越加密货币的区块链 文章关键词： 人工智能 技术趋势 相关新闻 徐小明 凯恩斯 占豪 花荣 金鼎 wu2198 丁大卫 易宪容 叶荣添 沙黾农 冯矿伟 趋势之友 空空道人 股市风云 股海光头 叶檀 凯恩斯 曹中铭 股民大张 宇辉战舰 股市风云 余岳桐 股海战神 郭一鸣 赵力行 叶檀 凯恩斯 曹中铭 股民大张 宇辉战舰 股市风云 余岳桐 股海战神 郭一鸣 赵力行 新浪简介|广告服务|About Sina 产品答疑|网站律师|SINA English Copyright © 1996-2024 SINA Corporation 新浪首页 语音播报 相关新闻 返回顶部\"}, {\"url\": \"https://www.toutiao.com/article/7426690213990138408/\", \"content\": \"《未来变革者：2025 年九大科技趋势研究报告》由 CB Insights 发布，该报告探讨了 2025 年可能改变世界的九大科技趋势，包括 AI 天气预测、超深钻探、AI 智能体市场、先进核推进、生物计算、大脑操控技术、量子优化投资组合、细胞与表观遗传重编程以及无 GPS 导航系统。\"}], [{\"url\": \"http://niis.cass.cn/webpic/web/niis/upload/2014/04/d20140430100736433.pdf\", \"content\": \"全球化、政治稳定性这两个因素对经济增长的影响。检验的结果表明:一个经济体全 球化程度的提高会显著地促进其经济增长,政治的稳定对经济增长的促进作用也非常 明显,全球化与政治稳定性在促进经济增长上存在替代效应。本项研究主要有以下两\"}, {\"url\": \"http://www.iwep.org.cn/cbw/cbw_wzxd/201404/t20140426_1903694.shtml\", \"content\": \"《世界经济与政治》2014年第4期 [pdf全文阅读] 论全球化、政治稳定性对经济增长的影响. 张中元 [内容提要] 在世界范围内全球化已不再是单纯的经济问题,其与政治稳定、社会进步、发展质量有着越来越密切的关系。\"}, {\"url\": \"http://ejournaliwep.cssn.cn/qkjj/sjjjyzz/2014nd4q_8178/201404/t20140414_4352944.shtml\", \"content\": \"作者利用全球128 个经济体在1975-2012 年间的相关数据,采用动态面板模型检验全球化与政治稳定性对经济增长的影响,结果发现:其一,一个经济体经济全球化、社会全球化和政治全球化程度的提高均会显著地促进其经济增长。其二,政治稳定对经济增长有明显的促进\"}, {\"url\": \"https://cj.sina.com.cn/articles/view/7830800370/1d2c087f2001026z9q\", \"content\": \"同时，技术革命对全球经济的影响日益显著，各国需要制定相应的应对策略来适应这一变革。 ... 中东地区的石油和天然气资源一直是地缘政治争夺的焦点，冲突不断导致能源供应的不稳定，进而影响到全球能源市场和价格。非洲等地区的资源争夺和民族分裂也\"}, {\"url\": \"https://xueqiu.com/1201669148/304593558\", \"content\": \"在全球化不断深化的今天，国家间的政治关系变得愈加错综复杂，地缘政治风险成为影响全球经济的重要因素。地缘政治风险通常是指国家间因为政治、军事或经济因素而引发的不确定性，这种不确定性会通过多个渠道渗透到全球经济的各个方面。近年来，我们可以看到一系列显著的地缘政治事件\"}]]\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Invalid request: Your request exceeded model token limit: 8192', 'type': 'invalid_request_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m明年最有发展的国家是？\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m events \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m      3\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, query)]},\n\u001b[0;32m      4\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m )\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevents\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mStep \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ai\\hello-langgraph\\graph_env\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1656\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   1650\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[0;32m   1652\u001b[0m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[1;32m-> 1656\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1657\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1658\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1659\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1660\u001b[0m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1661\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[0;32m   1663\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32md:\\ai\\hello-langgraph\\graph_env\\Lib\\site-packages\\langgraph\\pregel\\runner.py:167\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    165\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32md:\\ai\\hello-langgraph\\graph_env\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32md:\\ai\\hello-langgraph\\graph_env\\Lib\\site-packages\\langgraph\\utils\\runnable.py:408\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[0;32m    405\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    406\u001b[0m )\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32md:\\ai\\hello-langgraph\\graph_env\\Lib\\site-packages\\langgraph\\utils\\runnable.py:184\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[1;32m--> 184\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[28], line 34\u001b[0m, in \u001b[0;36mResponderWithRetries.respond\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     32\u001b[0m response \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(MAX_CRITIQUES):\n\u001b[1;32m---> 34\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattempt:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mattempt\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidator\u001b[38;5;241m.\u001b[39minvoke(response)\n",
      "File \u001b[1;32md:\\ai\\hello-langgraph\\graph_env\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3023\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3024\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3025\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3026\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\ai\\hello-langgraph\\graph_env\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5354\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5350\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[0;32m   5351\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5352\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5355\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5356\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5357\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ai\\hello-langgraph\\graph_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    285\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 286\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32md:\\ai\\hello-langgraph\\graph_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ai\\hello-langgraph\\graph_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    647\u001b[0m ]\n\u001b[0;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32md:\\ai\\hello-langgraph\\graph_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 633\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32md:\\ai\\hello-langgraph\\graph_env\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\ai\\hello-langgraph\\graph_env\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:689\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m     generation_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response\u001b[38;5;241m.\u001b[39mheaders)}\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 689\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response, generation_info)\n",
      "File \u001b[1;32md:\\ai\\hello-langgraph\\graph_env\\Lib\\site-packages\\openai\\_utils\\_utils.py:275\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ai\\hello-langgraph\\graph_env\\Lib\\site-packages\\openai\\resources\\chat\\completions.py:829\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    826\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    827\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    828\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m--> 829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ai\\hello-langgraph\\graph_env\\Lib\\site-packages\\openai\\_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1279\u001b[0m     )\n\u001b[1;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32md:\\ai\\hello-langgraph\\graph_env\\Lib\\site-packages\\openai\\_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ai\\hello-langgraph\\graph_env\\Lib\\site-packages\\openai\\_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1070\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'Invalid request: Your request exceeded model token limit: 8192', 'type': 'invalid_request_error'}}",
      "\u001b[0mDuring task with name 'revise' and id 'f7c49b16-ae5b-d693-882b-46d0c0309392'"
     ]
    }
   ],
   "source": [
    "query = \"明年最有发展的国家是？\"\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", query)]},\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "\n",
    "for i, step in enumerate(events):\n",
    "    print(f\"Step {i}\")\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7159e30c-728e-480d-8252-915404cc756d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congrats on building a Reflexion actor! I'll leave you with a few observations to save you some time when choosing which parts of this agent to adapt to your workflow:\n",
    "1. This agent trades off execution time for quality. It explicitly forces the agent to critique and revise the output over several steps, which usually (not always) increases the response quality but takes much longer to return a final answer\n",
    "2. The 'reflections' can be paired with additional external feedback (such as validators), to further guide the actor.\n",
    "3. In the paper, 1 environment (AlfWorld) uses external memory. It does this by storing summaries of the reflections to an external store and using them in subsequent trials/invocations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
